{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "def lake_model(b=0.42, q=2.0, mean=0.02, stdev=0.001, alpha=0.4, \n",
    "                      delta=0.98, nsamples=100, steps=100, **kwargs):    \n",
    "    '''runs the lake model for 1 stochastic realisation using specified \n",
    "    random seed.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    b : float\n",
    "        decay rate for P in lake (0.42 = irreversible)\n",
    "    q : float\n",
    "        recycling exponent\n",
    "    mean : float\n",
    "            mean of natural inflows\n",
    "    stdev : float\n",
    "            standard deviation of natural inflows\n",
    "    alpha : float\n",
    "            utility from pollution\n",
    "    delta : float\n",
    "            future utility discount rate\n",
    "    steps : int\n",
    "            the number of time steps (e.g., days)\n",
    "    \n",
    "    '''\n",
    "    X = np.zeros([steps,], dtype=np.float)\n",
    "    decisions = np.zeros([steps,], dtype=np.float)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        decisions[i] = kwargs[str(i)]\n",
    "    \n",
    "    Pcrit = brentq(lambda x: x**q/(1+x**q) - b*x, 0.01, 1.5)\n",
    "    \n",
    "    transformed_mean = log(mean**2 / sqrt(stdev**2 + mean**2))\n",
    "    transformed_sigma = sqrt(log(1.0 + stdev**2 / mean**2))\n",
    "    natural_inflows = np.random.lognormal(transformed_mean, transformed_sigma, size=steps)\n",
    "\n",
    "    for t in range(1, steps):\n",
    "        X[t] = (1-b)*X[t-1] + X[t-1]**q/(1+X[t-1]**q) + decisions[t-1] + natural_inflows[t-1]\n",
    "\n",
    "    reliability = np.sum(X < Pcrit)/steps\n",
    "    utility = np.sum(alpha*decisions*np.power(delta,np.arange(steps)))\n",
    "    inertia = np.sum(np.abs(np.diff(decisions)) < 0.01)/(steps-1)\n",
    "    return X, utility, inertia, reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "from libc.math cimport log, sqrt\n",
    "\n",
    "ctypedef np.float_t DTYPE_t\n",
    "\n",
    "\n",
    "@cython.cdivision(True)\n",
    "@cython.boundscheck(False) \n",
    "def cython_lake_model(float b=0.42, float q=2.0, float mean=0.02, \n",
    "                      float stdev=0.001, float alpha=0.4, float delta=0.98, \n",
    "                      int nsamples=100, int steps=100, **kwargs):    \n",
    "    '''runs the lake model for 1 stochastic realisation using specified \n",
    "    random seed.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    b : float\n",
    "        decay rate for P in lake (0.42 = irreversible)\n",
    "    q : float\n",
    "        recycling exponent\n",
    "    mean : float\n",
    "            mean of natural inflows\n",
    "    stdev : float\n",
    "            standard deviation of natural inflows\n",
    "    alpha : float\n",
    "            utility from pollution\n",
    "    delta : float\n",
    "            future utility discount rate\n",
    "    steps : int\n",
    "            the number of time steps (e.g., days)\n",
    "    seed : int, optional\n",
    "           seed for the random number generator\n",
    "    \n",
    "    '''\n",
    "    cdef float Pcrit, reliability, utility, inertia, transformed_mean, transformed_sigma\n",
    "    cdef int t, i\n",
    "    cdef np.ndarray[DTYPE_t, ndim=1] X = np.zeros([steps,], dtype=np.float)\n",
    "    cdef np.ndarray[DTYPE_t, ndim=1] decisions = np.zeros([steps,], dtype=np.float)\n",
    "    cdef np.ndarray[DTYPE_t, ndim=1] natural_inflows \n",
    "    \n",
    "    for i in range(steps):\n",
    "        decisions[i] = kwargs[str(i)]\n",
    "    \n",
    "    Pcrit = brentq(lambda x: x**q/(1+x**q) - b*x, 0.01, 1.5)\n",
    "    \n",
    "    transformed_mean = log(mean**2 / sqrt(stdev**2 + mean**2))\n",
    "    transformed_sigma = sqrt(log(1.0 + stdev**2 / mean**2))\n",
    "    natural_inflows = np.random.lognormal(transformed_mean, transformed_sigma, size=steps)\n",
    "\n",
    "    for t in range(1, steps):\n",
    "        X[t] = (1-b)*X[t-1] + X[t-1]**q/(1+X[t-1]**q) + decisions[t-1] + natural_inflows[t-1]\n",
    "\n",
    "    reliability = np.sum(X < Pcrit)/steps\n",
    "    utility = np.sum(alpha*decisions*np.power(delta,np.arange(steps)))\n",
    "    inertia = np.sum(np.abs(np.diff(decisions)) < 0.01)/(steps-1)\n",
    "    return X, utility, inertia, reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decisions = {str(i):0 for i in range(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "lake_model(**decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "cython_lake_model(**decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the use of cython here brings a lot less speedup that in the endogenous learning case. The reason for this is that each of the release decisions (100 in total) needs to be a separate keyword argument. This is a requirement imposed by the workbench. To make this easies, I use \\*\\*kwargs to wrap all decisions into a single dict that I can subsequently use to get the relevant decision. This \\*\\*kwargs notation is not convertable to C since C does not have variable length arguments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (RealParameter, ScalarOutcome, Constant)\n",
    "from ema_workbench.em_framework.model import Replicator, BaseModel\n",
    "\n",
    "#instantiate the model\n",
    "class ReplicatorModel(Replicator, BaseModel):\n",
    "    pass\n",
    "lake_model = ReplicatorModel('lakeproblem', function=cython_lake_model)\n",
    "lake_model.replications = 150\n",
    "\n",
    "#specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers\n",
    "lake_model.levers = [RealParameter(str(i), 0, 0.1) for i in range(100)]\n",
    "\n",
    "def process_p(values):\n",
    "    values = np.asarray(values)\n",
    "    values = np.mean(values, axis=0)\n",
    "    return np.max(values)\n",
    "\n",
    "#specify outcomes \n",
    "lake_model.outcomes = [ScalarOutcome('max_P', \n",
    "                                     kind=ScalarOutcome.MINIMIZE,\n",
    "                                     function=process_p\n",
    "                                    ),\n",
    "                       ScalarOutcome('utility', \n",
    "                                     kind=ScalarOutcome.MAXIMIZE,\n",
    "                                     function=np.mean\n",
    "                                    ),\n",
    "                       ScalarOutcome('inertia', \n",
    "                                     kind=ScalarOutcome.MAXIMIZE,\n",
    "                                     function=np.mean\n",
    "                                    ),\n",
    "                       ScalarOutcome('reliability', \n",
    "                                     kind=ScalarOutcome.MAXIMIZE,\n",
    "                                     function=np.mean\n",
    "                                    )]\n",
    "\n",
    "# override some of the defaults of the model\n",
    "lake_model.constants = [Constant('alpha', 0.41),\n",
    "                        Constant('nsamples', 100),\n",
    "                        Constant('steps', 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ema_workbench import MultiprocessingEvaluator, ema_logging, perform_experiments\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(policies=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "experiments, outcomes = results\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "x = outcomes['max_P']\n",
    "y = outcomes['utility']\n",
    "z = outcomes['reliability']\n",
    "\n",
    "ax.scatter(x, y, z, depthshade=False)\n",
    "\n",
    "ax.scatter(x, z, c='lightgrey', zdir='y', zs=2, depthshade=False)\n",
    "ax.scatter(y, z, c='lightgrey', zdir='x', zs=-0, depthshade=False)\n",
    "ax.scatter(x, y, c='lightgrey', zdir='z', zs=-0.5, depthshade=False)\n",
    "\n",
    "ax.set_xlabel(\"max_P\")\n",
    "ax.set_ylabel(\"utility\")\n",
    "ax.set_zlabel(\"reliability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference scenario optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework.optimization import to_dataframe\n",
    "\n",
    "class Callback(object):\n",
    "    '''Callable object for tracking progress of optimization over generations\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.progress = []\n",
    "        self.archive_history = []\n",
    "\n",
    "    def __call__(self, optimizer):\n",
    "        self.progress.append(optimizer.algorithm.archive.improvements)\n",
    "        \n",
    "        dvnames = optimizer.problem.parameter_names\n",
    "        outcome_names = optimizer.problem.outcome_names\n",
    "        \n",
    "        self.archive_history.append(to_dataframe(optimizer, dvnames,\n",
    "                                                 outcome_names))\n",
    "callback = Callback()\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    optimization_results = evaluator.optimize(searchover='levers', \n",
    "                      nfe=100000, epsilons=[0.05,]*len(lake_model.outcomes),\n",
    "                      callback=callback, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(callback.progress)\n",
    "ax.set_ylabel('$\\epsilon$-progress')\n",
    "ax.set_xlabel('generations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_opt = optimization_results['max_P']\n",
    "y_opt = optimization_results['utility']\n",
    "z_opt = optimization_results['reliability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_x = np.concatenate((x, x_opt))\n",
    "complete_y = np.concatenate((y, y_opt))\n",
    "complete_z = np.concatenate((z, z_opt))\n",
    "complete_inertia = np.concatenate((outcomes['inertia'], optimization_results['inertia']))\n",
    "labeling = np.asarray(['random guess',]*500+['optimization',]*z_opt.shape[0])\n",
    "data = {'max p':complete_x, 'utility':complete_y, 'reliability':complete_z, \n",
    "        'inertia':complete_inertia, 'type':labeling}\n",
    "\n",
    "combined = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(combined, hue='type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "x = outcomes['max_P']\n",
    "y = outcomes['utility']\n",
    "z = outcomes['reliability']\n",
    "\n",
    "x_opt = optimization_results['max_P']\n",
    "y_opt = optimization_results['utility']\n",
    "z_opt = optimization_results['reliability']\n",
    "\n",
    "# Axes limits\n",
    "pholims = (0, 2.6)\n",
    "utilims = (-0.5, 2.6)\n",
    "rellims = (0, 1.1)\n",
    "\n",
    "experiments, outcomes = results\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# setup plot\n",
    "ax.view_init(elev=20, azim=120)\n",
    "ax.set_xlim(pholims)\n",
    "ax.set_ylim(utilims)\n",
    "ax.set_zlim(rellims)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "x_arrow = Arrow3D(pholims, [utilims[1], utilims[1]], [0, 0],\n",
    "                  mutation_scale = 30, lw=2, arrowstyle=\"<|-\", color=\"k\")\n",
    "y_arrow = Arrow3D([pholims[0],pholims[0]], utilims, [0, 0],\n",
    "                  mutation_scale = 30, lw=2, arrowstyle=\"-|>\", color=\"k\")\n",
    "z_arrow = Arrow3D([0,0], [utilims[1], utilims[1]], rellims,\n",
    "                  mutation_scale = 30, lw=2, arrowstyle=\"-|>\", color=\"k\")\n",
    "ax.add_artist(x_arrow)\n",
    "ax.add_artist(y_arrow)\n",
    "ax.add_artist(z_arrow)\n",
    "\n",
    "# initial guesses\n",
    "x = outcomes['max_P']\n",
    "y = outcomes['utility']\n",
    "z = outcomes['reliability']\n",
    "\n",
    "ax.scatter(x, y, z, c='#3182bd', depthshade=False)\n",
    "\n",
    "c = '#deebf7' # '#9ecae1'\n",
    "# c = 'lightgrey'\n",
    "ax.scatter(x, z, c=c, zdir='y', zs=utilims[1], depthshade=False)\n",
    "ax.scatter(y, z, c=c, zdir='x', zs=pholims[0], depthshade=False)\n",
    "ax.scatter(x, y, c=c, zdir='z', zs=-0.1, depthshade=False)\n",
    "\n",
    "# optimization\n",
    "archive = callback.archive_history\n",
    "x_opt = archive[0]['max_P']\n",
    "y_opt = archive[0]['utility']\n",
    "z_opt = archive[0]['reliability']\n",
    "\n",
    "d3_scatter = ax.scatter(x_opt, y_opt, z_opt, c='#e6550d', depthshade=False)\n",
    "\n",
    "c = '#fee6ce' #'#fdae6b'\n",
    "xz_shadow = ax.scatter(x_opt, z_opt, c=c, zdir='y', zs=utilims[1], depthshade=False)\n",
    "yz_shadow = ax.scatter(y_opt, z_opt, c=c, zdir='x', zs=pholims[0], depthshade=False)\n",
    "xy_shadow = ax.scatter(x_opt, y_opt, c=c, zdir='z', zs=-0.1, depthshade=False)\n",
    "\n",
    "ax.set_xlabel(\"max_P\", fontsize=20)\n",
    "ax.set_ylabel(\"utility\", fontsize=20)\n",
    "ax.set_zlabel(\"reliability\", fontsize=20)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "def update(front):\n",
    "    x_opt = front['max_P'].values\n",
    "    y_opt = front['utility'].values\n",
    "    z_opt = front['reliability'].values\n",
    "    \n",
    "    d3_scatter._offsets3d = (x_opt, y_opt, z_opt)\n",
    "\n",
    "    x_offset = np.ones(x_opt.shape)*pholims[0]\n",
    "    y_offset = np.ones(x_opt.shape)*utilims[1]\n",
    "    z_offset = np.ones(x_opt.shape)*-0.1\n",
    "\n",
    "    xz_shadow._offsets3d = (x_opt, y_offset, z_opt)\n",
    "    yz_shadow._offsets3d = (x_offset, y_opt, z_opt)\n",
    "    xy_shadow._offsets3d = (x_opt, y_opt, z_offset)\n",
    "    return d3_scatter\n",
    "\n",
    "animated = animation.FuncAnimation(fig, update, \n",
    "                                   frames=callback.archive_history,\n",
    "                                   blit=False)\n",
    "plt.close(animated._fig)\n",
    "HTML(animated.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import save_results\n",
    "from io import BytesIO, StringIO\n",
    "import tarfile\n",
    "\n",
    "base = 'no_learning'\n",
    "animated.save('./data/{}.mp4'.format(base))\n",
    "optimization_results.to_csv('./data/{}.cvs'.format(base))\n",
    "save_results(results, './data/{}_guess.tar.gz'.format(base))\n",
    "pd.Series(callback.progress).to_csv('./data/{}_progress.csv'.format(base))\n",
    "\n",
    "file_name = './data/{}_archives.tar.gz'.format(base)\n",
    "with tarfile.open(file_name, 'w:gz') as z:\n",
    "    for i, entry in enumerate(callback.archive_history):\n",
    "        file_buffer = StringIO()\n",
    "        entry.to_csv(file_buffer)\n",
    "        \n",
    "        csv_as_string = file_buffer.getvalue()\n",
    "        fh = BytesIO(csv_as_string.encode('UTF-8'))\n",
    "        tarinfo = tarfile.TarInfo(str(i)+'.csv')\n",
    "        tarinfo.size = len(csv_as_string)\n",
    "        \n",
    "        z.addfile(tarinfo, fh)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
